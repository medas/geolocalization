{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Table of Content**\n\n1. [Notebook setup](#Notebook setup)\n1. [Data retrieval](#Data retrieval)\n    1. [Population Data](#Population Data)\n    1. [Real Estate Data](#Real Estate Data)\n    1. [Web scrapping the list of Neighborhoods](#Web scrapping the list of Neighborhoods)\n"},{"metadata":{},"cell_type":"markdown","source":"Install the python packages needed for the data analysis"},{"metadata":{},"cell_type":"markdown","source":"1. > #### Notebook setup<a id=\"Notebook setup\"/>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.io.json import json_normalize\nimport folium\nfrom geopy.geocoders import Nominatim\nimport requests\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport seaborn as sns\n\nimport requests # library to handle requests\nimport numpy as np # library to handle data in a vectorized manner\nimport random # library for random number generation\n\nfrom geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n    \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\nimport re\n\nimport time\nimport folium # plotting library\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', 500)\n\n#libraries for Data preprocess\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\n\n#librarie for ML Clustring\nfrom sklearn.cluster import KMeans\n\nimport requests\nimport io\n\nLIMIT = 100 # limit of number of venues returned by Foursquare API","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!conda install -c conda-forge geopy --yes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. > ### Data retrieval<a id=\"Data retrieval\"></a>"},{"metadata":{},"cell_type":"markdown","source":"We will need three sources of data:\n* Population data\n* Real estate data\n* Venue location and profile"},{"metadata":{},"cell_type":"markdown","source":"2. 1. > #### Population data<a id=\"Population Data\"></a>"},{"metadata":{},"cell_type":"markdown","source":"We  will need to retrieve the population distribution by the neighborhoods of Lisbon from a public access database. The data is from the year 2011, this is the date of the last national census in Portugal and is available on the national statistics authority website."},{"metadata":{},"cell_type":"markdown","source":"To retrieve the data from the website, we need to add the *headers={'User-Agent': 'Mozilla/5.0'}* option to the *requests.get* call because the website requires it to allow us to download the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"req = requests.get('https://www.ine.pt/clientFiles/Tx229qn_YCWF3G-boMIgFv1ysVK3XljoZXw-264d_32562.csv', headers={'User-Agent': 'Mozilla/5.0'}).text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A quick inspection of the file, show us that the file has a few lines on the begining and at the end that are the data description and need to be skipped before we load the data in a data frame."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(req[1:600])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The file has 53 lines of data, the total number of neighborhoods, the information comes from an inspection of the file but also from the website. So we can skipe the first 14 lines and load just the next 53 lines. "},{"metadata":{"trusted":true},"cell_type":"markdown","source":"We will also name the data frame headers according to the data in the file. We will only keep the relevant columns for the data analysis and skip the other ones. Then we will review what was loaded and clean the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"req = requests.get('https://www.ine.pt/clientFiles/Tx229qn_YCWF3G-boMIgFv1ysVK3XljoZXw-264d_32562.csv', headers={'User-Agent': 'Mozilla/5.0'}).text\nheaders = ['Data reference period','id', 'Neighborhood','Total','15 - 19 years', '20 - 24 years', '25 - 29 years','30 - 34 years','empty']\ntype = {'Neighborhood': 'string'}\npopulation_data = pd.read_csv(io.StringIO(req), skiprows=14, nrows=53, header=None, names=headers, sep =':|;', engine='python', usecols=list(range(2,8)), dtype=type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"population_data.Neighborhood[:6].apply(lambda x: '-{}-'.format(x)) #check what was loaded in the neighborhood column.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see above, we need to strip the white spaces from the start of the neighborhood column."},{"metadata":{"trusted":true},"cell_type":"code","source":"population_data.Neighborhood = population_data.Neighborhood.apply(lambda x: x.strip())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"population_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"population_data.head().sort_values('Neighborhood')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. 2. > #### Real Estate data<a id=\"Real Estate Data\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Next we will retrieve from the same source, the average value per square meter of dwellings sales in the city of Lisbon by neighborhood. The data is from the last quarter 2019.\nWe will use the same strategy describe above to retrieve the data.\nWe need to skip the first 12 lines of the file and only load the next 24 lines."},{"metadata":{"trusted":true},"cell_type":"code","source":"req = requests.get('http://www.ine.pt/clientFiles/doiruoM_g0OE783CqcQFlrT_gZ5W4b37oicowX1X_93336.csv', headers={'User-Agent': 'Mozilla/5.0'}).text\nheaders = ['Neighborhood','Median value per m2 of dwellings sales']\ntype = {'Neighborhood': 'string'}\nreal_estate = pd.read_csv(io.StringIO(req), skiprows=12, nrows=24, header=None, names= headers, sep =':|;', engine='python', usecols=[1,2], dtype = type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_estate.Neighborhood[:6].apply(lambda x: '-{}-'.format(x)) #check what was loaded in the neighborhood column.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_estate.Neighborhood = real_estate.Neighborhood.apply(lambda x: x.strip())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_estate.head().sort_values('Neighborhood')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_estate.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You may notice that these data are display a different set of Neighborhood. This is because between 2011 and 2019 there was a administrative territorial reset of the Neighborhood in Portugal and manny were merged.\n\nSo the first data frame is showing a population distribution for an outdated administrative division of the city. We will need to web scrap a wikipedia page to get the relation between the current Neighborhoods and the these one."},{"metadata":{},"cell_type":"markdown","source":"3. > ### Web scrapping the list of Neighborhoods<a id=\"Web scrapping the list of Neighborhoods\"/>"},{"metadata":{},"cell_type":"markdown","source":"We will get the information we need to merge the two data frames from a wikipedia page that relates the two sets of Neighborhood names. "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"website_url = requests.get('https://pt.wikipedia.org/wiki/Lista_de_freguesias_de_Lisboa').text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"soup = BeautifulSoup(website_url,'lxml')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"headers = ['Neighborhood', 'Old Neighborhood']\ntype = {'Neighborhood': 'string', 'Old Neighborhood': 'string'}\nneighborhoods = pd.DataFrame(columns = headers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for row in soup.table.find_all('tr'):\n    row_data=[]\n    for data in row.find_all('td'):\n        row_data.append(data.text.strip())\n    #print(\"row_data\", row_data)\n    if len(row_data) == 10 :\n        neighborhoods.loc[len(neighborhoods)] = [row_data[2], row_data[7]]\n        neighboor = row_data[2]\n    elif len(row_data) == 5 and row_data[0] != '62':\n        neighborhoods.loc[len(neighborhoods)] = [neighboor, row_data[2]]\n    elif len(row_data) == 5 and row_data[0] == '62':\n        neighborhoods.loc[len(neighborhoods)] = [row_data[2],'']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighborhoods.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighborhoods = neighborhoods.astype('string')\nneighborhoods.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def retrieve_first_word_of(line):\n    return line.split('[')[0].split('(')[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighborhoods['Neighborhood'] = neighborhoods['Neighborhood'].apply(lambda x: retrieve_first_word_of(x).strip())\nneighborhoods['Old Neighborhood'] = neighborhoods['Old Neighborhood'].apply(lambda x: retrieve_first_word_of(x).strip())\nneighborhoods = neighborhoods.astype('string')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighborhoods","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. > ### Data Preparation<a id=\"Data Preparation\"/>"},{"metadata":{},"cell_type":"markdown","source":"We will merge the data sets, starting with the population and the Neighborhoods and then we will merge the resulting data frame with the real estate data frame."},{"metadata":{"trusted":true},"cell_type":"code","source":"population_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"population_data.rename(columns={'Neighborhood': 'Old Neighborhood'}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Neighborhood_population = pd.merge(neighborhoods, population_data, on='Old Neighborhood')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Neighborhood_population.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Neighborhood_population.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = df_Neighborhood_population.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = df_Neighborhood_population[(columns[2:])].loc[29]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"olivais = (stats * 0.6).astype(int)\nparque = (stats * 0.4).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parque","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Neighborhood_population = df_Neighborhood_population.drop([29], axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#parque['Neighborhood'] = \"Parque das Nações\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parque","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = [\"Parque das Nações\", \"\"]\na.extend(parque.tolist())\n\nb = [\"Olivais\", \"Santa Maria dos Olivais\"]\nb.extend(olivais.tolist())\ndfnew = pd.DataFrame([a,b], columns=df_Neighborhood_population.columns)\ndf_Neighborhood_population = df_Neighborhood_population.append(dfnew)\ndf_Neighborhood_population.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Neighborhood_population.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighborhoods = neighborhoods.groupby(['Neighborhood'])['Old Neighborhood'].apply(', '.join).reset_index()\nneighborhoods.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Neighborhood_real_estate = pd.merge(neighborhoods, real_estate, on='Neighborhood')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Neighborhood_real_estate.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Neighborhood_population.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_Neighborhood_population.groupby(['Neighborhood']).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Neighborhood_population_grouped = df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Neighborhood_population_grouped.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a issue with merge. Since one of the old neighboorhoods, \"Santa Maria dos Olivais\", we need to split the data between the two new neighborhoods. \nWe know that the split was around 60% to the new \"Olivais\" neighborhood and 40% to the new \"Parque das Nações\" nwighborhood. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.merge(df_Neighborhood_real_estate, df_Neighborhood_population_grouped, on = \"Neighborhood\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colunms=df2[['Median value per m2 of dwellings sales', 'Total', '15 - 19 years', '20 - 24 years', '25 - 29 years', '30 - 34 years']].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2[['Neighborhood', 'total score']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n!{sys.executable} -m pip install geocoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import geocoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nACCESS_TOKEN = user_secrets.get_secret(\"ACCESS_TOKEN\")\nCLIENT_ID = user_secrets.get_secret(\"CLIENT_ID\")\nCLIENT_SECRET = user_secrets.get_secret(\"CLIENT_SECRET\")\ngoogle_api_key = user_secrets.get_secret(\"google_api_key\")\n\nVERSION = '20180605' # Foursquare API version","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = geocoder.google('Lisboa, Portugal', key=google_api_key)\ng.latlng\nprint(g.latlng)\nlatitude, longitude = g.latlng","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_latlng(postal_code):\n    # initialize your variable to None\n    lat_lng_coords = None\n    # loop until you get the coordinates\n    while(lat_lng_coords is None):\n        g = geocoder.google('{}, Lisboa, Portugal'.format(postal_code), key=google_api_key)\n        lat_lng_coords = g.latlng\n    return lat_lng_coords[0],lat_lng_coords[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['coord'] = df2.Neighborhood.apply(lambda x: get_latlng(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['Latitude'] = df2.coord.apply(lambda x: x[0])\ndf2['Longitude'] = df2.coord.apply(lambda x: x[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.drop(\"coord\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"address = 'Lisbon, Portugal'\n\ngeolocator = Nominatim(user_agent=\"lisbon_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of the city of Lisbon are {}, {}.'.format(latitude, longitude))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create map of Lisbon using latitude and longitude values\nmap_lisbon = folium.Map(location=[latitude, longitude], zoom_start=14)\n\n# add markers to map\nfor lat, lng, Neighborhood in zip(df2['Latitude'], df2['Longitude'], df2['Neighborhood']):\n    label = '{}'.format(Neighborhood)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_lisbon)  \n    \nmap_lisbon","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"downtown_venues = getNearbyVenues(names=df2['Neighborhood'], latitudes=df2['Latitude'], longitudes=df2['Longitude'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(downtown_venues.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"downtown_venues.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"downtown_venues.groupby('Neighborhood').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are {} uniques categories.'.format(len(downtown_venues['Venue Category'].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one hot encoding\ndowntown_onehot = pd.get_dummies(downtown_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# drop the Neighborhood column (that doesn't have the names at the moment)\n#downtown_onehot = downtown_onehot.drop(['Neighborhood'], axis = 1)\n\n# add neighborhood column back to dataframe\ndowntown_onehot['Neighborhood'] = downtown_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [downtown_onehot.columns[-1]]  + list(downtown_onehot.columns[:-1])\ndowntown_onehot = downtown_onehot[fixed_columns]\n\ndowntown_onehot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"downtown_onehot.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"downtown_grouped = downtown_onehot.groupby('Neighborhood').mean().reset_index()\ndowntown_grouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"downtown_grouped.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_top_venues = 5\n\nfor hood in downtown_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = downtown_grouped[downtown_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = downtown_grouped['Neighborhood']\n\nfor ind in np.arange(downtown_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(downtown_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set number of clusters\nkclusters = 5\n\ndowntown_grouped_clustering = downtown_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(downtown_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:15] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\ndowntown_merged = df2\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ndowntown_merged = downtown_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\ndowntown_merged.head() # check the last columns!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.rename(columns={'Median value per m2 of dwellings sales': 'real estate value'}, inplace=True)\ndf2.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"url = 'https://opendata.arcgis.com/datasets/e0ebb7f5038e4114979f73cbf66321ef_1.geojson'\n\nneighborhoods_json=requests.get(url).json()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!wget --quiet https://opendata.arcgis.com/datasets/e0ebb7f5038e4114979f73cbf66321ef_1.geojson lisbon_json\n#lisbon_geo = r'lisbon_json'\ndef makeMap(center = [latitude, longitude], zoom = 12):\n    neighMap = folium.Map(location = center, zoom_start = zoom)#, tiles='cartodbpositron')\n\n    # choropleth map without data to outline the neighborhoods    \n    choropleth = folium.Choropleth(\n        geo_data = neighborhoods_json,#neighborhoods_json,\n        data = df2,\n        columns = ['Neighborhood', 'real estate value'],\n        key_on ='feature.properties.NOME',\n        name = 'choropleth',\n        fill_color = 'YlOrRd',\n        fill_opacity = 0.7, \n        line_opacity = 0.3,\n        legend_name = 'Real Estate Value',\n        line_color = 'black',\n        highlight = True,\n    ).add_to(neighMap)\n\n    #choropleth.geojson.add_child(folium.features.GeoJsonTooltip(['Neighborhood'],labels=False))\n    \n    return neighMap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lisbon_map = makeMap()\n\n# add approximate business center markers to map\nfor lat, lng, neighborhood in zip(df2['Latitude'], df2['Longitude'], df2['Neighborhood']):\n    label = '{}'.format(neighborhood)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=10,\n        popup=label,\n        fill=True,\n        parse_html=False,\n        color='blue'\n    ).add_to(lisbon_map)\n    \n# display map\nlisbon_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define a function that extracts the category of the venue\n\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The business types criteria specified by the client: 'Restaurants', 'Cafés' and 'Bars'"},{"metadata":{},"cell_type":"markdown","source":"![](http://)> Let's look at their frequency of occurance for all the Lisbon neighborhoods, isolating the categorical venues\nThese are the venue types that the client wants to have an abundant density of in the ideal store locations. I've used a violin plot from the seaborn library - it is a great way to visualise frequency distribution datasets, they display a density estimation of the underlying distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical plot\n# Explore a plot of this data (a violin plot is used which is a density estimation of the underlying distribution).\n# The top 3 venue types as specified by the client for each neighborhood are used for the plotting.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfig = plt.figure(figsize=(50,25))\nsns.set(font_scale=1.1)\n\nax = plt.subplot(3,1,1)\nsns.violinplot(x=\"Neighborhood\", y=\"Restaurant\", data=downtown_onehot, cut=0);\nplt.xlabel(\"\")\n\nax = plt.subplot(3,1,2)\nsns.violinplot(x=\"Neighborhood\", y=\"Café\", data=downtown_onehot, cut=0);\nplt.xlabel(\"\")\n\nplt.subplot(3,1,3)\nsns.violinplot(x=\"Neighborhood\", y=\"Bakery\", data=downtown_onehot, cut=0);\n\nax.text(-1.0, 3.1, 'Frequency distribution for the top 3 venue categories for each neighborhood', fontsize=60)\nplt.savefig (\"Distribution_Frequency_Venues_3_categories.png\", dpi=240)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(50,25))\nsns.set(font_scale=1.1)\n\nax = plt.subplot(4,1,1)\nsns.violinplot(x=\"Neighborhood\", y=\"Restaurant\", data=downtown_onehot, cut=0);\nplt.xlabel(\"\")\n\nax = plt.subplot(4,1,2)\nsns.violinplot(x=\"Neighborhood\", y=\"Café\", data=downtown_onehot, cut=0);\nplt.xlabel(\"\")\n\nplt.subplot(4,1,3)\nsns.violinplot(x=\"Neighborhood\", y=\"Bakery\", data=downtown_onehot, cut=0);\n\nplt.subplot(4,1,4)\nsns.violinplot(x=\"Neighborhood\", y=\"Bookstore\", data=downtown_onehot, cut=0);\n\nax.text(-1.0, 3.1, 'Frequency distribution for the top 3 venue categories for each neighborhood (click to enlage)', fontsize=60)\nplt.savefig (\"Distribution_Frequency_Venues_3_categories.png\", dpi=240)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So our candidates are \n* Alvalade\n* Areeiro\n* Avenidas Novas\n* Campo de Ourique\n* Campolide\n* Parque das Nações"},{"metadata":{"trusted":true},"cell_type":"code","source":"violin_data = ['Alvalade', 'Areeiro', 'Avenidas Novas', 'Campo de Ourique', 'Campolide', 'Parque das Nações']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There a re still a lot of neighborhoods to analyse. We have other source data to include in our analysis.\nWhere yourger people live. So let display it on the map."},{"metadata":{"trusted":true},"cell_type":"code","source":"def population_map(center = [latitude, longitude], zoom = 12):\n    map = folium.Map(location = center, zoom_start = zoom)\n\n    # choropleth map without data to outline the neighborhoods    \n    choropleth = folium.Choropleth(\n        geo_data = neighborhoods_json,#neighborhoods_json,\n        data = df2,\n        columns = ['Neighborhood', 'Total'],\n        key_on ='feature.properties.NOME',\n        name = 'choropleth',\n        fill_color = 'YlOrRd',\n        fill_opacity = 0.7, \n        line_opacity = 0.3,\n        legend_name = 'Total of younger Population distribution',\n        line_color = 'black',\n        highlight = True,\n    ).add_to(map)\n\n    return map\n\nyounger_pop_map = population_map()\n\n# add approximate neighborhood center markers to map\nfor lat, lng, neighborhood in zip(df2['Latitude'], df2['Longitude'], df2['Neighborhood']):\n    label = '{}'.format(neighborhood)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=10,\n        popup=label,\n        fill=True,\n        parse_html=False,\n        color='blue'\n    ).add_to(younger_pop_map)\n    \n# display map\nyounger_pop_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['real estate score'] = df2['real estate value'].apply(lambda value: 0.7 * value/df2['real estate value'].mean())\ndf2['population score']  = df2['Total'].apply(lambda value: 0.3 * value/df2['Total'].mean())\ndf2['total score'] = df2['population score'] + df2['real estate score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def population_map(center = [latitude, longitude], zoom = 12):\n    map = folium.Map(location = center, zoom_start = zoom)\n\n    # choropleth map without data to outline the neighborhoods    \n    choropleth = folium.Choropleth(\n        geo_data = neighborhoods_json,#neighborhoods_json,\n        data = df2,\n        columns = ['Neighborhood', 'total score'],\n        key_on ='feature.properties.NOME',\n        name = 'choropleth',\n        fill_color = 'YlOrRd',\n        fill_opacity = 0.7, \n        line_opacity = 0.3,\n        legend_name = 'Best score',\n        line_color = 'black',\n        highlight = True,\n    ).add_to(map)\n\n    return map\n\nyounger_pop_map = population_map()\n\n# add approximate neighborhood center markers to map\nfor lat, lng, neighborhood in zip(df2['Latitude'], df2['Longitude'], df2['Neighborhood']):\n    label = '{}'.format(neighborhood)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=10,\n        popup=label,\n        fill=True,\n        parse_html=False,\n        color='blue'\n    ).add_to(younger_pop_map)\n    \n# display map\nyounger_pop_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.set_index(df2.Neighborhood, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = df2.loc[violin_data]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def population_map(center = [latitude, longitude], zoom = 12):\n    map = folium.Map(location = center, zoom_start = zoom)\n\n    # choropleth map without data to outline the neighborhoods    \n    choropleth = folium.Choropleth(\n        geo_data = neighborhoods_json,\n        data = df2,\n        columns = ['Neighborhood', 'total score'],\n        key_on ='feature.properties.NOME',\n        name = 'choropleth',\n        fill_color = 'YlOrRd',\n        fill_opacity = 0.7, \n        line_opacity = 0.3,\n        legend_name = 'Best score',\n        line_color = 'black',\n        highlight = True,\n    ).add_to(map)\n\n    return map\n\nyounger_pop_map = population_map()\n\n# add approximate neighborhood center markers to map\n\n# display map\n\nfor lat, lng, neighborhood in zip(df3['Latitude'], df3['Longitude'], df3['Neighborhood']):\n    folium.CircleMarker(\n        location=[lat, lng],\n        radius=20,\n        fill=True,\n        parse_html=True,\n        color='green',\n        fill_color='#3186cc'\n    ).add_to(younger_pop_map)\n    \nyounger_pop_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = folium.Map(\n    location=[latitude, longitude],\n    zoom_start=12  # Limited levels of zoom for free Mapbox tiles.\n)\n\nfolium.GeoJson(\n   neighborhoods_json,\n    name='geojson'\n).add_to(m)\nm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}